{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AIMO 3 Competition Submission\n",
        "\n",
        "This notebook uses the ToolOrchestra-based multi-domain solver to solve AIMO 3 problems.\n",
        "\n",
        "## System Overview\n",
        "- **7 Domain Solvers**: Geometry (25 theorems), Algebra, Number Theory, Combinatorics, Graph Theory, Analysis, Symbolic\n",
        "- **ToolOrchestra Integration**: RL-based intelligent tool orchestration\n",
        "- **Stability Tracking**: Optional (disabled for speed in competition)\n",
        "\n",
        "## Competition Requirements\n",
        "- CPU Notebook: ≤ 9 hours runtime\n",
        "- GPU Notebook: ≤ 5 hours runtime\n",
        "- Internet: Disabled\n",
        "- Submission file: Generated by API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "# In Kaggle, working directory is /kaggle/working\n",
        "project_root = Path('/kaggle/working')\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Add kaggle_evaluation to path if needed\n",
        "kaggle_eval_path = Path('/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation')\n",
        "if kaggle_eval_path.exists() and str(kaggle_eval_path) not in sys.path:\n",
        "    sys.path.insert(0, str(kaggle_eval_path.parent))\n",
        "\n",
        "# Import Kaggle evaluation API\n",
        "try:\n",
        "    import kaggle_evaluation.core.templates\n",
        "    import aimo_3_gateway\n",
        "except ImportError:\n",
        "    # Fallback: try importing from local path\n",
        "    import importlib.util\n",
        "    gateway_path = project_root / 'ai-mathematical-olympiad-progress-prize-3' / 'kaggle_evaluation' / 'aimo_3_gateway.py'\n",
        "    if gateway_path.exists():\n",
        "        spec = importlib.util.spec_from_file_location('aimo_3_gateway', gateway_path)\n",
        "        aimo_3_gateway = importlib.util.module_from_spec(spec)\n",
        "        spec.loader.exec_module(aimo_3_gateway)\n",
        "    \n",
        "    templates_path = project_root / 'ai-mathematical-olympiad-progress-prize-3' / 'kaggle_evaluation' / 'core' / 'templates.py'\n",
        "    if templates_path.exists():\n",
        "        spec = importlib.util.spec_from_file_location('templates', templates_path)\n",
        "        templates = importlib.util.module_from_spec(spec)\n",
        "        spec.loader.exec_module(templates)\n",
        "        kaggle_evaluation = type('kaggle_evaluation', (), {'core': type('core', (), {'templates': templates})()})()\n",
        "\n",
        "# Import our solver\n",
        "from src.orchestration import create_aimo_orchestrator\n",
        "\n",
        "print(\"✓ Imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Solver\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ToolOrchestra adapter (best solver)\n",
        "# Disable stability tracking for speed in competition\n",
        "orchestrator = create_aimo_orchestrator(\n",
        "    use_toolorchestra=True,\n",
        "    measure_stability=False,  # Disabled for speed\n",
        "    track_orchestration_stability=False,  # Disabled for speed\n",
        ")\n",
        "\n",
        "print(\"✓ Solver initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Predict Function\n",
        "\n",
        "The Kaggle evaluation API calls a `predict` function with problem data.\n",
        "We need to extract the problem statement and return the answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "from typing import Any\n",
        "\n",
        "def predict(data_batch: pl.DataFrame) -> pl.DataFrame:\n",
        "    \"\"\"\n",
        "    Predict function called by Kaggle evaluation API.\n",
        "    \n",
        "    Args:\n",
        "        data_batch: DataFrame with 'id' and 'problem' columns\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame with 'id' and 'answer' columns\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for row in data_batch.iter_rows(named=True):\n",
        "        problem_id = row['id']\n",
        "        problem_statement = row['problem']\n",
        "        \n",
        "        try:\n",
        "            # Solve the problem\n",
        "            answer = orchestrator.solve(problem_statement, problem_id=problem_id)\n",
        "            \n",
        "            # Ensure answer is in valid range [0, 99999]\n",
        "            answer = max(0, min(99999, int(answer)))\n",
        "            \n",
        "        except Exception as e:\n",
        "            # Fallback to 0 on error\n",
        "            print(f\"Error solving {problem_id}: {e}\")\n",
        "            answer = 0\n",
        "        \n",
        "        results.append({\n",
        "            'id': problem_id,\n",
        "            'answer': answer\n",
        "        })\n",
        "    \n",
        "    # Return as DataFrame\n",
        "    return pl.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Inference Server\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AIMO3InferenceServer(kaggle_evaluation.core.templates.InferenceServer):\n",
        "    \"\"\"Inference server for AIMO 3 competition.\"\"\"\n",
        "    \n",
        "    def _get_gateway_for_test(self, data_paths=None, *args, **kwargs):\n",
        "        \"\"\"Get gateway for local testing.\"\"\"\n",
        "        return aimo_3_gateway.AIMO3Gateway(data_paths)\n",
        "\n",
        "# Create inference server with our predict function\n",
        "inference_server = AIMO3InferenceServer(predict)\n",
        "\n",
        "print(\"✓ Inference server initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Evaluation\n",
        "\n",
        "In Kaggle environment, this will automatically:\n",
        "1. Receive problems from the Gateway\n",
        "2. Call our predict function\n",
        "3. Generate submission file\n",
        "\n",
        "**Note:** This cell will block until all problems are processed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start the inference server\n",
        "# In Kaggle environment, this will run until all problems are solved\n",
        "inference_server.serve()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Local Testing (Optional)\n",
        "\n",
        "For local testing, you can run the gateway manually:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to test locally\n",
        "# inference_server.run_local_gateway(\n",
        "#     data_paths=('/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv',)\n",
        "# )\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
