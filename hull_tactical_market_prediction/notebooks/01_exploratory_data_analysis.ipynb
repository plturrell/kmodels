{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hull Tactical Market Prediction - Exploratory Data Analysis\n",
    "\n",
    "This notebook explores the training data to understand:\n",
    "- Target variable distribution and characteristics\n",
    "- Feature distributions and correlations\n",
    "- Temporal patterns and trends\n",
    "- Missing value patterns\n",
    "- Outliers and anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = Path.cwd().parent / \"data\" / \"raw\"\n",
    "train_csv = data_dir / \"train.csv\"\n",
    "test_csv = data_dir / \"test.csv\"\n",
    "\n",
    "print(f\"Loading data from {data_dir}\")\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_test = pd.read_csv(test_csv)\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")\n",
    "print(f\"\\nColumns: {list(df_train.columns[:10])}...\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Groups\n",
    "\n",
    "The features are organized into groups:\n",
    "- **D (Date):** D1-D9 - Date/time features\n",
    "- **E (Economic):** E1-E20 - Economic indicators\n",
    "- **I (Interest):** I1-I9 - Interest rate features\n",
    "- **M (Market):** M1-M18 - Market features\n",
    "- **P (Price):** P1-P13 - Price features\n",
    "- **S (Spread):** S1-S12 - Spread features\n",
    "- **V (Volatility):** V1-V13 - Volatility features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize features\n",
    "feature_groups = {\n",
    "    'Date': [c for c in df_train.columns if c.startswith('D')],\n",
    "    'Economic': [c for c in df_train.columns if c.startswith('E')],\n",
    "    'Interest': [c for c in df_train.columns if c.startswith('I')],\n",
    "    'Market': [c for c in df_train.columns if c.startswith('M')],\n",
    "    'Price': [c for c in df_train.columns if c.startswith('P')],\n",
    "    'Spread': [c for c in df_train.columns if c.startswith('S')],\n",
    "    'Volatility': [c for c in df_train.columns if c.startswith('V')],\n",
    "}\n",
    "\n",
    "print(\"Feature Group Sizes:\")\n",
    "for group, cols in feature_groups.items():\n",
    "    print(f\"  {group:12s}: {len(cols):2d} features\")\n",
    "\n",
    "target_cols = ['forward_returns', 'risk_free_rate', 'market_forward_excess_returns']\n",
    "print(f\"\\nTarget columns: {target_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target statistics\n",
    "print(\"Target Variable Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "df_train[target_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, col in enumerate(target_cols):\n",
    "    ax = axes[idx]\n",
    "    df_train[col].hist(bins=50, ax=ax, edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(f'{col} Distribution')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.axvline(df_train[col].median(), color='red', linestyle='--', \n",
    "               label=f'Median: {df_train[col].median():.4f}')\n",
    "    ax.axvline(df_train[col].mean(), color='green', linestyle='--',\n",
    "               label=f'Mean: {df_train[col].mean():.4f}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for normality\n",
    "print(\"\\nNormality Tests (Shapiro-Wilk):\")\n",
    "for col in target_cols:\n",
    "    stat, p_value = stats.shapiro(df_train[col].dropna()[:5000])  # Sample for speed\n",
    "    print(f\"  {col:35s}: p-value = {p_value:.6f} {'(Normal)' if p_value > 0.05 else '(Not Normal)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forward returns over time\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Forward returns time series\n",
    "axes[0].plot(df_train['date_id'], df_train['forward_returns'], linewidth=0.8, alpha=0.7)\n",
    "axes[0].set_title('Forward Returns Over Time')\n",
    "axes[0].set_xlabel('Date ID')\n",
    "axes[0].set_ylabel('Forward Returns')\n",
    "axes[0].axhline(0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling statistics\n",
    "window = 21  # ~1 month\n",
    "rolling_mean = df_train['forward_returns'].rolling(window=window).mean()\n",
    "rolling_std = df_train['forward_returns'].rolling(window=window).std()\n",
    "\n",
    "axes[1].plot(df_train['date_id'], rolling_mean, label=f'{window}-day Mean', linewidth=1.5)\n",
    "axes[1].fill_between(df_train['date_id'], \n",
    "                      rolling_mean - rolling_std, \n",
    "                      rolling_mean + rolling_std, \n",
    "                      alpha=0.3, label=f'{window}-day Std')\n",
    "axes[1].set_title(f'Forward Returns - {window}-Day Rolling Statistics')\n",
    "axes[1].set_xlabel('Date ID')\n",
    "axes[1].set_ylabel('Forward Returns')\n",
    "axes[1].axhline(0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing value percentages\n",
    "missing_pct = (df_train.isnull().sum() / len(df_train) * 100).sort_values(ascending=False)\n",
    "missing_pct = missing_pct[missing_pct > 0]\n",
    "\n",
    "if len(missing_pct) > 0:\n",
    "    print(f\"Features with missing values: {len(missing_pct)}\")\n",
    "    print(\"\\nTop 20 features by missing percentage:\")\n",
    "    print(missing_pct.head(20))\n",
    "    \n",
    "    # Plot missing values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_pct.head(30).plot(kind='bar', color='steelblue', edgecolor='black')\n",
    "    plt.title('Missing Value Percentage by Feature (Top 30)')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Missing %')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âœ“ No missing values in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target\n",
    "feature_cols = [c for c in df_train.columns if c not in ['date_id'] + target_cols]\n",
    "correlations = df_train[feature_cols + ['forward_returns']].corr()['forward_returns'].drop('forward_returns')\n",
    "correlations = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 Features by Correlation with Forward Returns:\")\n",
    "print(correlations.head(20))\n",
    "\n",
    "# Plot top correlations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top positive correlations\n",
    "top_pos = df_train[feature_cols + ['forward_returns']].corr()['forward_returns'].drop('forward_returns').sort_values(ascending=False).head(15)\n",
    "top_pos.plot(kind='barh', ax=axes[0], color='green', edgecolor='black')\n",
    "axes[0].set_title('Top 15 Positive Correlations with Forward Returns')\n",
    "axes[0].set_xlabel('Correlation')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Top negative correlations\n",
    "top_neg = df_train[feature_cols + ['forward_returns']].corr()['forward_returns'].drop('forward_returns').sort_values(ascending=True).head(15)\n",
    "top_neg.plot(kind='barh', ax=axes[1], color='red', edgecolor='black')\n",
    "axes[1].set_title('Top 15 Negative Correlations with Forward Returns')\n",
    "axes[1].set_xlabel('Correlation')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Group Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average correlation by feature group\n",
    "group_correlations = {}\n",
    "for group, cols in feature_groups.items():\n",
    "    valid_cols = [c for c in cols if c in df_train.columns]\n",
    "    if valid_cols:\n",
    "        corrs = df_train[valid_cols + ['forward_returns']].corr()['forward_returns'].drop('forward_returns')\n",
    "        group_correlations[group] = corrs.abs().mean()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "pd.Series(group_correlations).sort_values(ascending=False).plot(kind='bar', color='purple', edgecolor='black')\n",
    "plt.title('Average Absolute Correlation with Forward Returns by Feature Group')\n",
    "plt.xlabel('Feature Group')\n",
    "plt.ylabel('Average |Correlation|')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Group Importance (by avg correlation):\")\n",
    "for group, corr in sorted(group_correlations.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {group:12s}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpe Ratio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sharpe ratio over time (rolling window)\n",
    "window = 252  # ~1 year\n",
    "\n",
    "rolling_sharpe = (\n",
    "    df_train['forward_returns'].rolling(window=window).mean() / \n",
    "    df_train['forward_returns'].rolling(window=window).std()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(df_train['date_id'], rolling_sharpe, linewidth=1.5, label=f'{window}-day Rolling Sharpe')\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "plt.axhline(1, color='green', linestyle='--', linewidth=1, alpha=0.5, label='Sharpe = 1')\n",
    "plt.axhline(-1, color='orange', linestyle='--', linewidth=1, alpha=0.5, label='Sharpe = -1')\n",
    "plt.title(f'Rolling Sharpe Ratio ({window}-day window)')\n",
    "plt.xlabel('Date ID')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overall Sharpe ratio\n",
    "overall_sharpe = df_train['forward_returns'].mean() / df_train['forward_returns'].std()\n",
    "print(f\"\\nOverall Sharpe Ratio: {overall_sharpe:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Hull Tactical Market Prediction - Dataset Summary\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Training samples: {len(df_train)}\")\n",
    "print(f\"Test samples: {len(df_test)}\")\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"\\nFeature Groups:\")\n",
    "for group, cols in feature_groups.items():\n",
    "    print(f\"  {group:12s}: {len(cols):2d} features\")\n",
    "print(f\"\\nTarget Statistics:\")\n",
    "print(f\"  Forward Returns:\")\n",
    "print(f\"    Mean: {df_train['forward_returns'].mean():.6f}\")\n",
    "print(f\"    Std:  {df_train['forward_returns'].std():.6f}\")\n",
    "print(f\"    Min:  {df_train['forward_returns'].min():.6f}\")\n",
    "print(f\"    Max:  {df_train['forward_returns'].max():.6f}\")\n",
    "print(f\"  Sharpe Ratio: {overall_sharpe:.4f}\")\n",
    "print(f\"\\nMissing Values: {len(missing_pct)} features with missing data\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

